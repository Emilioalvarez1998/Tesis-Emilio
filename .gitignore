###############################################################################
####################### ANÁLISIS ESTADÍSTICO TESIS ############################
###############################################################################

# Resetear
rm(list=ls())

# No considerar notación ciéntifica
options(scipen=999)

# Cargar paquetes 
library(rstudioapi)  # Área de trabajo
library(readxl)      # Abrir archivos xlsx
library(tidyverse)   # Tratamiento de datos
library(psych)       # Análisis descriptivo
library(skimr)       # Análisis exploratorio
library(readstata13) # Abrir archivos dta
library(AER)         # Modelos 2SLS
library(modelsummary)# Resumen de regresiones
library(plm)         # Datos de panel
library(stargazer)   # Salidad de modelos
library(data.table)  # Función rbindlist
library(lmtest)      # Coeftest
library(tseries)     # Supuestos
library(car)         # Supuestos

# Abrir directorio (Donde está el archivo y los datos)
setwd(dirname(getActiveDocumentContext()$path))

# Esquema análisis
eq <- read_excel("BBDD/Esquema.xlsx",sheet=1)
eq2 <- read_excel("BBDD/Esquema.xlsx",sheet=2)
eq3 <- read_excel("BBDD/Esquema.xlsx",sheet="Hoja4")

# Tratamiento de datos
bd <- unique(eq$region) %>% 
  lapply(function(x){
    (if(x %in% c("Metropolitana","Coquimbo","Ohiggins")){
      read_excel(paste0("BBDD/CBR_",x,".xlsx"),skip=9)
    }else{read.dta13(paste0("BBDD/CBR_",x,".dta"))}) %>% 
      as_tibble() %>% 
      rename_all(function(x){gsub(" ", "",tolower(chartr('áéíóúñ','aeioun',x)))}) %>% 
      filter(tipodetransaccion=="COMPRAVENTA") %>% 
      mutate_at(vars(year:day),as.integer) %>% 
      left_join(read.dta13("BBDD/UF.dta"), by=c("year","month","day")) %>% 
      distinct() %>% 
      filter(!is.na(uf)) %>% # Equivalente a filtro match 3 en este caso
      filter(unidadmoneda=="PESOS"|unidadmoneda=="UF") %>%
      filter(unidaddecaudal!="NO INDICA") %>% 
      filter(as.numeric(caudalpromedio)>=0.05) %>% 
      mutate(caudalpromedio=as.numeric(caudalpromedio),
             precio_uf_caudal=case_when(
               unidadmoneda=="PESOS" ~ (valortotaldelatransaccion/uf)/caudalpromedio,
               unidadmoneda=="UF"    ~ valortotaldelatransaccion/caudalpromedio,
               TRUE ~ as.numeric(NA)),
             region=x) %>% 
      left_join(eq,by=c("region","fuente")) %>% 
      distinct() %>% 
      mutate(fuente=fuente.aj) %>% 
      dplyr::select(-fuente.aj) %>% 
      filter(fuente %in% names(table(eq$fuente.aj[which(eq$region %in% x)]))) %>% 
      group_by(month,year,region,fuente,naturalezadelagua) %>% # ,tipodederecho,ejerciciodelderecho
      summarise(mean_precio=mean(precio_uf_caudal)) %>% #,sd_precio=sd(precio_uf_caudal),median_precio=median(precio_uf_caudal)
      ungroup() %>% 
      mutate(log_precio_uf_caudal=log(mean_precio))}) %>% 
  rbindlist() %>% 
  as_tibble() %>% 
  dplyr::select(region,everything()) %>% 
  left_join(read.dta13("BBDD/CaudalesCR2.dta") %>% dplyr::select(-fecha),by=c("year","month","fuente")) %>% 
  distinct() %>% 
  left_join(eq2,by="fuente") %>% 
  distinct() %>% 
  mutate(month=as.character(month),
         year=as.character(year),
         log_caudal=log(caudal),#log_caudal2=log_caudal^2,
         edate=as.character(paste0(year,ifelse(as.numeric(month)<10,paste0("0",month),month))),
         sequia=ifelse(as.integer(year)>=2010,1,0),
         fuente=paste0(fuente,"-",naturalezadelagua)
         #cluster=paste0(region,"-",edate)
  ) %>% 
  #fuente=paste0(region,"-",fuente)) %>% 
  na.omit() %>% 
  filter(!(naturalezadelagua %in% c("NO INDICA","SUBTERRANEA")))
#dplyr::select(-c("tipodederecho","ejerciciodelderecho","caudal","mean_precio","month","year","sequia"))
#filter(log_caudal>0 | log_precio_uf_caudal>0) %>% 
bdc <- bd %>% 
  left_join(
    eq3 %>% 
      select(region,alta_agricultura),
    by="region")  

#library(writexl)
#write_xlsx(bdc,"Datos_agricultura.xlsx")


bd0 <- bd %>% 
  left_join(
    eq3 %>% 
      select(region,alta_agricultura),
    by="region") %>% 
  filter(alta_agricultura==0)

bd1 <- bd %>% 
  left_join(
    eq3 %>% 
      select(region,alta_agricultura),
    by="region") %>% 
  filter(alta_agricultura==1)

bd3 <- bd %>% 
  left_join(
    eq3 %>% 
      select(region,alta_agricultura),
    by="region")

# Guardar datos
library(writexl)
#write_xlsx(bd,"Datos_análisis.xlsx")

# Análisis exploratorio
skim(bd)
skim(bd3)

# Análisis bivariado
cor(bd$log_caudal,bd$log_precio_uf_caudal)
cor(bd$caudal,bd$mean_precio)
cor(bd$log_caudal,bd$sequia)
cor(bd$log_caudal,bd$stress)
cor(bd3$log_caudal,bd3$alta_agricultura)


# Análisis gráfico
plot(bd$log_caudal,bd$log_precio_uf_caudal,col="black",main="Relación lineal entre valor uf y caudal")
abline(lm(bd$log_precio_uf_caudal~bd$log_caudal),col="red",lty=2,lwd=3)

# boxplot(bd$log_precio_uf_caudal~bd$sequia)
# boxplot(bd$log_precio_uf_caudal~bd$naturalezadelagua,col=c(3,2),main="Precio por naturaleza del agua")

# Ho: Las medianas de ambos grupos son iguales
# Ha: Las medianas de ambos grupos son distintos
#wilcox.test(bd$log_precio_uf_caudal~bd$sequia)
#wilcox.test(bd$log_precio_uf_caudal~bd$tipodederecho)

# Ho: Todas las medianas son iguales.
# Ha: A lo menos una mediana es distinta al resto.
kruskal.test(bd$log_precio_uf_caudal~bd$fuente)
#kruskal.test(bd$log_precio_uf_caudal~bd$naturalezadelagua)

# 1) MODELO ALTA_AGRICULTURA=0
panel <- bd %>% pdata.frame(index = c('fuente','edate'))
panel2 <- bd3 %>% pdata.frame(index = c('fuente','edate'))

# Data de panel
m1<-lm(log_precio_uf_caudal~log_caudal*sequia*stress, data=bd0); summary(m1)
coeftest(m1, vcov=vcovHC(m1, type="HC0")) 

re<-plm(log_precio_uf_caudal~log_caudal*sequia*stress, data=panel, effect = "twoways",model="random"); summary(re)
coeftest(re, vcov=vcovHC(re,type="HC0",cluster="group")) 

wi<-plm(log_precio_uf_caudal~alta_agricultura*sequia*estres, data=panel2, effect = "individual",model="within"); summary(wi)
coeftest(wi, vcov=vcovHC(wi, type="HC0", cluster="group")) 
fixef(wi)







m7<-lm(log_precio_uf_caudal~alta_agricultura*sequia*stress, data=bd3); summary(m7)

# Supuestos
# 1. Normalidad
# Ho: Normalidad vs Ha: NO normalidad
jarque.bera.test(m1$residuals)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con normalidad.
# 2. Homocedasticidad
# Ho: Homocedasticidad vs Ha: Heterocedasticidad
bptest(m1)
# El test arroja un valor-p>0.05 por lo que no se rechaza Ho, es decir no hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo cumple con homocedasticidad.
# 3. Autocorrelación
# Ho: Independencia vs Ha: Autocorrelación
dwtest(m1)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con independencia.
# 4. Multicolinealidad
# Si el vif es menor a 5 hay multicolinealidad baja (Eso es lo que se espera)
vif(m1)
# La mayorá de los VIF son mayores a 5 por lo que hay evidencia de multicolinealidad alta. Es decir, el
# modelo no cumple con este supuesto.

# Modelo inválido.

# 2) MODELO ALTA_AGRICULTURA=1

# Data de panel
m2<-lm(log_precio_uf_caudal~log_caudal*sequia*stress, data=bd1); summary(m2)
coeftest(m2, vcov=vcovHC(m2, type="HC0")) 

m99<-lm(log_precio_uf_caudal~alta_agricultura*sequia*stress+log_caudal, data=bd3); summary(m99)

# Supuestos
# 1. Normalidad
# Ho: Normalidad vs Ha: NO normalidad
jarque.bera.test(m2$residuals)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con normalidad.
# 2. Homocedasticidad
# Ho: Homocedasticidad vs Ha: Heterocedasticidad
bptest(m2)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con homocedasticidad.
# 3. Autocorrelación
# Ho: Independencia vs Ha: Autocorrelación
dwtest(m2)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con independencia.
# 4. Multicolinealidad
# Si el vif es menor a 5 hay multicolinealidad baja (Eso es lo que se espera)
vif(m2)
# La mayorá de los VIF son mayores a 5 por lo que hay evidencia de multicolinealidad alta. Es decir, el
# modelo no cumple con este supuesto.

# Modelo inválido

# 3) MODELO RELACIÓN PRECIO ALTA Y BAJA AGRICULTURA

# Data de panel
m3<-lm(log_precio_uf_caudal~alta_agricultura*stress, data=bd3); summary(m3)
coeftest(m3, vcov=vcovHC(m3, type="HC0")) 

m54<-lm(stress~alta_agricultura*log_precio_uf_caudal, data=bd3); summary(m54)

m66<-lm(stress~alta_agricultura*log_caudal, data=bd3); summary(m66)

# Supuestos
# 1. Normalidad
# Ho: Normalidad vs Ha: NO normalidad
jarque.bera.test(m3$residuals)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con normalidad.
# 2. Homocedasticidad
# Ho: Homocedasticidad vs Ha: Heterocedasticidad
bptest(m3)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con homocedasticidad.
# 3. Autocorrelación
# Ho: Independencia vs Ha: Autocorrelación
dwtest(m3)
# El test arroja un valor-p<0.05 por lo que se rechaza Ho, es decir hay evidencia suficiente como para
# confirmar que se rechaza Ho. Es decir, el modelo no cumple con independencia.
# 4. Multicolinealidad
# Si el vif es menor a 5 hay multicolinealidad baja (Eso es lo que se espera)
vif(m3)
# La mayorá de los VIF son mayores a 5 por lo que hay evidencia de multicolinealidad alta. Es decir, el
# modelo no cumple con este supuesto.

# Modelo inválido.

# 4) MODELO STRESS ALTA
m4.0<-glm(stress~alta_agricultura*log_precio_uf_caudal, data=bd3,binomial(link = "logit")); summary(m4)
m4<-glm(stress~alta_agricultura*log_precio_uf_caudal, data=bd3,binomial(link = "probit")); summary(m4)
coeftest(m4, vcov=vcovHC(m4, type="HC0")) 

library(caret)
library(pROC)       # Evaluar curva de ROC

# Bondad de ajuste del modelo
PseudoR2(m4, which = c("all"))

# Predicciones data test
bd3$pred <- round(predict(m4, bd3, type="response"),0)

# curva roc en test
roc_test_log <- roc(bd3$stress, bd3$pred)

# Gráfico curva de ROC
plot.roc( roc_test_log, legacy.axes = TRUE, print.thres = "best", print.auc = TRUE,
          auc.polygon = FALSE, max.auc.polygon = FALSE, auc.polygon.col = "gainsboro",
          col = 2, grid = TRUE , main ="Curva de ROC Modelo probit")

#Matriz de confusión
caret::confusionMatrix(as.factor(bd3$pred),as.factor(bd3$stress))

# Odds ratios
# exp(cbind("Odds ratio" = coef(m4), confint.default(m4, level = 0.95)))

# Marginales
# Interpretación efectos marginales 
# http://www.colpos.mx/wb_pdf/Montecillo/Economia/llseminario/Doc/13_MC_Maribel_Aviles_Cano.pdf

# Cálculo de interacción aparte, pues las funciones de marginales no las detectan.
data = bd3 %>% mutate(alta_agricultura_x_log_precio_uf_caudal=alta_agricultura*log_precio_uf_caudal)

# Cálculo de las marginales
library(marginaleffects)
m44<-glm(stress~alta_agricultura*log_precio_uf_caudal+alta_agricultura_x_log_precio_uf_caudal, data=data,binomial(link = "probit")); summary(m4)
summary(marginaleffects(m44))

library(stargazer)
stargazer(m1,m2,m3,type="text") # Lineales  
stargazer(m4,m54,type="text")  # Binarias
stargazer(m3,re,m7="text")
stargazer(m3,re,m7,type= "text")

stargazer(m4,m54,m66,type= "text")

stargazer(m99,type= "text")

stargazer(wi,type= "text")

